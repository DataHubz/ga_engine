# V4 Fused Key-Switch Kernel Optimization

**Date**: 2025-11-10
**Status**: âœ… COMPLETE

## Overview

Implemented fused Metal GPU kernels for key-switch operations in hoisted automorphism rotations. The optimization combines inverse NTT final scaling with inverse twist application, eliminating GPU kernel dispatch overhead and intermediate buffer round-trips.

## Performance Results

### V4 Geometric Product (Full End-to-End)

| Configuration | Time | vs Baseline | Cumulative |
|--------------|------|-------------|------------|
| **Baseline** (hoisting only) | 12.35s | - | - |
| + Pre-NTT key caching | 11.22s | +10.1% | +10.1% |
| + Fused iNTT+untwist kernel | **10.60s** | +6.5% | **+16.5%** |

**Total speedup from all optimizations: 1.165Ã— (16.5% improvement)**

### Detailed Timing Breakdown

```
Baseline (12.35s):
â”œâ”€ Hoisting (decompose+NTT): 30% saved vs non-hoisted
â”œâ”€ Key-switch operations: ~50% of rotation time
â”‚  â”œâ”€ Pointwise multiply: ~15%
â”‚  â”œâ”€ Inverse NTT: ~25%
â”‚  â””â”€ Inverse twist: ~10%
â””â”€ Other operations: ~20%

After Fused Kernel (10.60s):
â”œâ”€ Pre-NTT key caching: ~15-20% saved on key transforms
â”œâ”€ Fused iNTT+untwist: ~6.5% saved on kernel dispatch overhead
â””â”€ Remaining: Mostly pointwise multiply and modular arithmetic
```

## Implementation Details

### 1. Metal GPU Inverse Twist Wrapper

Added Rust wrapper for existing Metal `ntt_apply_inverse_twist` kernel:

**File**: [src/clifford_fhe_v2/backends/gpu_metal/ntt.rs:618-670](src/clifford_fhe_v2/backends/gpu_metal/ntt.rs#L618-L670)

```rust
pub fn apply_inverse_twist_gpu(&self, coeffs: &mut [u64]) -> Result<(), String> {
    // Convert coeffs and psi_inv_powers to Montgomery domain
    // Dispatch Metal kernel: coeffs[i] *= Ïˆ^{-i} mod q
    // Convert result back to standard domain
}
```

**Shader**: [src/clifford_fhe_v2/backends/gpu_metal/shaders/ntt.metal:486-497](src/clifford_fhe_v2/backends/gpu_metal/shaders/ntt.metal#L486-L497)

Updated to use 4-arg Montgomery `mul_mod(a, b, q, q_inv)`.

### 2. Fused iNTT Final Scale + Inverse Twist Kernel

Created new Metal kernel that combines three operations into one:

**Shader**: [src/clifford_fhe_v2/backends/gpu_metal/shaders/ntt.metal:515-554](src/clifford_fhe_v2/backends/gpu_metal/shaders/ntt.metal#L515-L554)

```metal
kernel void ntt_inverse_final_scale_and_untwist(
    device ulong* coeffs [[buffer(0)]],
    constant ulong* psi_inv_powers [[buffer(1)]],
    constant uint& n [[buffer(2)]],
    constant ulong& q [[buffer(3)]],
    constant ulong& n_inv_mont [[buffer(4)]],
    constant ulong& q_inv [[buffer(5)]],
    uint gid [[thread_position_in_grid]]
)
```

**Operations (all in Montgomery domain)**:
1. Compute bit-reversed index
2. Scale by n^{-1}: `val *= n_inv_mont`
3. Apply inverse twist: `val *= Ïˆ^{-i}`
4. Write back swapped values

### 3. Rust Wrapper for Fused Kernel

**File**: [src/clifford_fhe_v2/backends/gpu_metal/ntt.rs:711-790](src/clifford_fhe_v2/backends/gpu_metal/ntt.rs#L711-L790)

```rust
pub fn inverse_and_untwist_fused(&self, evals: &mut [u64]) -> Result<(), String> {
    // Step 1: Execute inverse butterfly stages (unchanged)
    for stage in (0..log_n).rev() { /* ... */ }

    // Step 2: FUSED bit-reversal + scaling + inverse twist
    let kernel = self.device.get_function("ntt_inverse_final_scale_and_untwist")?;
    // Dispatch single fused kernel
}
```

### 4. Updated Key-Switch Helper

**File**: [src/clifford_fhe_v2/backends/gpu_metal/hoisting.rs:597-634](src/clifford_fhe_v2/backends/gpu_metal/hoisting.rs#L597-L634)

```rust
fn multiply_ntt_and_intt(...) -> Result<Vec<u64>, String> {
    for (prime_idx, _q) in moduli.iter().enumerate() {
        // Pointwise multiply in NTT domain
        ntt_ctx.pointwise_multiply(&a_poly, &b_poly, &mut result_poly)?;

        // FUSED inverse NTT + untwist (single optimized operation!)
        ntt_ctx.inverse_and_untwist_fused(&mut result_poly)?;
    }
}
```

## Key Technical Decisions

### Why Fuse Final Scale + Untwist?

1. **Both are simple pointwise operations** - no inter-element dependencies
2. **Same memory access pattern** - bit-reversal swap on same buffer
3. **Small kernel overhead** - fusion eliminates one GPU dispatch (~50-100Î¼s)
4. **No intermediate buffer** - saves GPU readback/writeback

### Why Not Fuse More Operations?

The inverse NTT butterfly stages **cannot be fused** with final scale because:
- Multi-stage algorithm requires global synchronization between stages
- Metal's `threadgroup_barrier` only works within a threadgroup (not globally)
- Each butterfly stage must complete before the next begins

### Montgomery Domain Strategy

All operations stay in Montgomery domain throughout:
- Pointwise multiply: `(a*R) Â· (b*R) Â· R^{-1} = (aÂ·b)Â·R`
- iNTT butterfly: Montgomery multiply with twiddles
- Final scale: `val Â· n_inv_mont` where `n_inv_mont = n^{-1}Â·R`
- Inverse twist: `val Â· Ïˆ^{-i}_mont` where `Ïˆ^{-i}_mont = Ïˆ^{-i}Â·R`
- Only convert to standard domain at final readback

## Verification

All tests pass with exact numerical agreement:

```
cargo test --test test_geometric_operations_v4 --features v4,v2-gpu-metal --no-default-features

âœ“ 2. Geometric Product (a âŠ— b) [10.60s] [exact]
```

## Optimization Roadmap Progress

| Optimization | Target | Achieved | Status |
|--------------|--------|----------|--------|
| Automorphism hoisting | 25-30% | 29.9% | âœ… Complete |
| Pre-NTT key caching | 15-20% | 10.1% | âœ… Complete |
| Fused key-switch kernels | 5-10% | 6.5% | âœ… Complete |
| **Total V4 speedup** | **~45%** | **16.5%** | ðŸŸ¡ In Progress |

### Next Optimization Opportunities

1. **Batched RNS operations** (~5-8%)
   - Process all RNS primes in single GPU call
   - Eliminate per-prime extract/store loops
   - Requires batched kernel variants

2. **BSGS butterfly packing** (~30-40%)
   - Baby-step giant-step decomposition
   - Reduces rotation count from O(n) to O(âˆšn)
   - Architecture change, not just kernel optimization

3. **Better GPU memory management** (~3-5%)
   - Reuse GPU buffers across operations
   - Reduce allocation overhead
   - Pipeline multiple operations

## Architecture Notes

### 100% Metal GPU Execution

All arithmetic operations run on Metal GPU:
- âœ… Forward NTT with twist
- âœ… Inverse NTT with untwist (fused!)
- âœ… Pointwise multiplication
- âœ… Galois automorphism permutation
- âœ… Rotation key application

No CPU loops for modular arithmetic (only data extraction/storage).

### RNS Slot-Major Layout

Data stored in slot-major format for V4:
```
[coeff0_prime0, coeff0_prime1, coeff0_prime2, coeff1_prime0, ...]
```

This requires per-prime extraction but enables efficient Metal GPU operations.

## Lessons Learned

1. **Kernel fusion wins are modest** (~5-10% per fusion)
   - Metal GPU dispatch overhead is relatively low (~50-100Î¼s)
   - Main bottleneck is modular arithmetic throughput, not dispatch

2. **Pre-computation matters more** (10-20% gains)
   - Pre-NTT key caching saves real compute work
   - Memory is cheap, compute is expensive

3. **Algorithm changes win big** (30-40%+ potential)
   - Hoisting saved 30% by eliminating redundant NTTs
   - BSGS would save 30-40% by reducing rotation count

4. **Montgomery domain is essential**
   - All GPU kernels use Montgomery arithmetic
   - Conversion only at boundaries (CPU â†” GPU)

## Related Documents

- [V4_HOISTING_INTEGRATION.md](V4_HOISTING_INTEGRATION.md) - Hoisting implementation
- [PRE_NTT_KEY_CACHING_COMPLETE.md](PRE_NTT_KEY_CACHING_COMPLETE.md) - Pre-NTT caching
- [V4_OPTIMIZATION_ROADMAP.md](V4_OPTIMIZATION_ROADMAP.md) - Full optimization plan

## Testing

Run the full V4 test suite:

```bash
cargo test --test test_geometric_operations_v4 --features v4,v2-gpu-metal --no-default-features -- --nocapture
```

Run hoisting-specific tests:

```bash
cargo test --test test_hoisting_sanity_check --features v2,v2-gpu-metal --no-default-features -- --nocapture
```

## Summary

Successfully implemented fused key-switch kernels that combine inverse NTT final scaling with inverse twist application. The optimization provides 6.5% speedup on top of previous improvements, bringing total V4 geometric product speedup to **16.5%** (12.35s â†’ 10.60s).

The fused kernel demonstrates the value of eliminating GPU dispatch overhead, though the gains are modest compared to algorithmic improvements like hoisting and pre-computation. Future work should focus on BSGS butterfly decomposition for larger speedups.
